# Machine Learning Notebooks

This repository contains Jupyter notebooks for various machine learning assignments, focusing on key algorithms and concepts. Each notebook includes detailed explanations, mathematical foundations, and implementations in Python.

## Notebooks

### 1. Decision Trees
- **Description**: This notebook explores the concept of Decision Trees, a popular algorithm for classification and regression tasks. It includes visualizations of the tree structure and explanations of how decisions are made based on features.
- **Key Concepts**: Splitting criteria, overfitting, pruning, and tree visualization.

### 2. Information Gain
- **Description**: This notebook delves into Information Gain, a metric used to determine the effectiveness of an attribute in classifying data. It discusses entropy and how Information Gain is calculated to create optimal splits in Decision Trees.
- **Key Concepts**: Entropy, Information Gain calculation, and feature selection.

### 3. K-Nearest Neighbors (KNN)
- **Description**: This notebook covers the K-Nearest Neighbors algorithm, a simple yet effective method for classification and regression. It includes implementation details and discussions on distance metrics.
- **Key Concepts**: Distance measures (Euclidean, Manhattan), choosing the value of K, and classification tasks.

### 4. Linear Regression and Gradient Descent
- **Description**: This notebook focuses on Linear Regression, a foundational algorithm for predictive modeling, and Gradient Descent, a crucial optimization algorithm. It explains how to fit a linear model to data, evaluate its performance, and optimize it using Gradient Descent.
- **Key Concepts**: Cost function, gradient descent optimization, evaluation metrics (MSE, RÂ²), and convergence.

### 5. Logistic Regression and Neural Networks (MLP)
- **Description**: This notebook introduces Logistic Regression and explores Neural Networks, specifically Multilayer Perceptrons (MLP). It provides insights into classification problems and the role of activation functions in neural networks.
- **Key Concepts**: Sigmoid function, backpropagation, and multi-class classification.

### 6. Multivariate Gaussian Distribution and EM Algorithm
- **Description**: This notebook discusses Multivariate Gaussian Distributions and the Expectation-Maximization (EM) Algorithm. It includes applications in clustering and modeling probabilistic distributions.
- **Key Concepts**: Covariance matrices, contour plots, and iterative parameter estimation.

## Mathematical Foundations
This repository also covers essential mathematical concepts, including:
- **Vectors**: Understanding vector representation and operations crucial for machine learning algorithms.
- **Probability**: Fundamental probability concepts that underpin many machine learning techniques.
- **Linear Algebra**: Key linear algebra concepts relevant to data representation and transformations in machine learning.
- **Calculus**: Derivatives, gradients, and their applications in optimization algorithms like Gradient Descent.

## Installation

To run the Jupyter notebooks, you will need to have Jupyter installed. You can install it via pip:

```bash
pip install jupyter
